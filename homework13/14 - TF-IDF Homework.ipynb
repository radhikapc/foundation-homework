{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all of the things you need to import!\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 14 (or so): TF-IDF text analysis and clustering\n",
    "\n",
    "Hooray, we kind of figured out how text analysis works! Some of it is still magic, but at least the **TF** and **IDF** parts make a little sense. Kind of. Somewhat.\n",
    "\n",
    "No, just kidding, we're *professionals* now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Congressional Record\n",
    "\n",
    "The [Congressional Record](https://en.wikipedia.org/wiki/Congressional_Record) is more or less what happened in Congress every single day. Speeches and all that. A good large source of text data, maybe?\n",
    "\n",
    "Let's pretend it's totally secret but we just got it leaked to us in a data dump, and we need to check it out. It was leaked from [this page here](http://www.cs.cornell.edu/home/llee/data/convote.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'curl' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# If you'd like to download it through the command line...\n",
    "#!curl -O http://www.cs.cornell.edu/home/llee/data/convote/convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And then extract it through the command line...\n",
    "#!tar -zxf convote_v1.1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can explore the files if you'd like, but we're going to get the ones from `convote_v1.1/data_stage_one/development_set/`. It's a bunch of text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convote_v1.1/data_stage_one/development_set\\\\052_400011_0327014_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set\\\\052_400011_0327025_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set\\\\052_400011_0327044_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set\\\\052_400011_0327046_DON.txt',\n",
       " 'convote_v1.1/data_stage_one/development_set\\\\052_400011_1479036_DON.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob finds files matching a certain filename pattern\n",
    "import glob\n",
    "\n",
    "# Give me all the text files\n",
    "paths = glob.glob('convote_v1.1/data_stage_one/development_set/*')\n",
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So great, we have 702 of them. Now let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'convote_v1.1/data_stage_one/development_set\\\\052_400011_0327014_DON.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches = []\n",
    "for path in paths:\n",
    "    with open(path) as speech_file:\n",
    "        speech = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': speech_file.read()\n",
    "        }\n",
    "    speeches.append(speech)\n",
    "speeches_df = pd.DataFrame(speeches)\n",
    "#speeches_df.head()\n",
    "speeches_df['pathname'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we had the `texts` variable. For the homework can just do `speeches_df['content']` to get the same sort of list of stuff.\n",
    "\n",
    "**Take a look at the contents of the first 5 speeches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    mr. chairman , i thank the gentlewoman for yie...\n",
       "1    mr. chairman , i want to thank my good friend ...\n",
       "2    mr. chairman , i rise to make two fundamental ...\n",
       "3    mr. chairman , reclaiming my time , let me mak...\n",
       "4    mr. chairman , i thank my distinguished collea...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts =speeches_df['content']\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing our analysis\n",
    "\n",
    "Use the `sklearn` package and a plain boring `CountVectorizer` to get a list of all of the tokens used in the speeches. If it won't list them all, that's ok! Make a dataframe with those terms as columns.\n",
    "\n",
    "**Be sure to include English-language stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xc = count_vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<702x9106 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 56106 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>...</th>\n",
       "      <th>9091</th>\n",
       "      <th>9092</th>\n",
       "      <th>9093</th>\n",
       "      <th>9094</th>\n",
       "      <th>9095</th>\n",
       "      <th>9096</th>\n",
       "      <th>9097</th>\n",
       "      <th>9098</th>\n",
       "      <th>9099</th>\n",
       "      <th>9100</th>\n",
       "      <th>9101</th>\n",
       "      <th>9102</th>\n",
       "      <th>9103</th>\n",
       "      <th>9104</th>\n",
       "      <th>9105</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 9106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     10    11    \\\n",
       "0     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "   12    13    14    ...   9091  9092  9093  9094  9095  9096  9097  9098  \\\n",
       "0     0     1     0  ...      0     0     0     0     0     0     0     0   \n",
       "1     0     0     0  ...      0     0     0     0     0     0     0     0   \n",
       "2     0     0     0  ...      0     0     0     0     0     0     0     0   \n",
       "\n",
       "   9099  9100  9101  9102  9103  9104  9105  \n",
       "0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0  \n",
       "\n",
       "[3 rows x 9106 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xc.toarray()).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>00007</th>\n",
       "      <th>018</th>\n",
       "      <th>050</th>\n",
       "      <th>092</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>108th</th>\n",
       "      <th>109th</th>\n",
       "      <th>10th</th>\n",
       "      <th>11</th>\n",
       "      <th>110</th>\n",
       "      <th>...</th>\n",
       "      <th>yields</th>\n",
       "      <th>york</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>youth</th>\n",
       "      <th>yuan</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroing</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zigler</th>\n",
       "      <th>zirkin</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoellick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 9106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  00007  018  050  092  10  100  106  107  108  108th  109th  10th  11  \\\n",
       "0    0      0    0    0    0   0    0    0    0    0      0      0     0   1   \n",
       "1    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "2    0      0    0    0    0   0    0    0    0    0      0      0     0   0   \n",
       "\n",
       "   110    ...     yields  york  yorkers  young  younger  youngsters  youth  \\\n",
       "0    0    ...          0     0        0      0        0           0      0   \n",
       "1    0    ...          0     0        0      0        0           0      0   \n",
       "2    0    ...          0     0        0      0        0           0      0   \n",
       "\n",
       "   yuan  zero  zeroing  zeros  zigler  zirkin  zoe  zoellick  \n",
       "0     0     0        0      0       0       0    0         0  \n",
       "1     0     0        0      0       0       0    0         0  \n",
       "2     0     0        0      0       0       0    0         0  \n",
       "\n",
       "[3 rows x 9106 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc_feature= pd.DataFrame(Xc.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "Xc_feature.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, it's **far** too big to even look at. Let's try to get a list of features from a new `CountVectorizer` that only takes the top 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    \n",
    "    words = re.sub(r\"[^A-Za-z]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    #print(words)\n",
    "    return words\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['act', 'allow', 'amend', 'american', 'amp', 'ani', 'appropri', 'associ', 'balanc', 'base', 'becaus', 'believ', 'chairman', 'children', 'china', 'civil', 'colleagu', 'committe', 'congress', 'continu', 'countri', 'court', 'day', 'debat', 'discrimin', 'doe', 'educ', 'elect', 'faith', 'feder', 'fund', 'gentleman', 'good', 'govern', 'gt', 'h', 'ha', 'head', 'help', 'hous', 'import', 'includ', 'issu', 'just', 'know', 'law', 'lawsuit', 'legisl', 'like', 'make', 'mani', 'member', 'million', 'mr', 'nation', 'nbsp', 'need', 'new', 'offer', 'onli', 'organ', 'peopl', 'polici', 'program', 'protect', 'provid', 'provis', 'r', 'religi', 'repres', 'requir', 'right', 'rule', 's', 'say', 'school', 'servic', 'speaker', 'start', 'state', 'support', 'teacher', 'thank', 'thi', 'think', 'time', 'today', 'trade', 'unit', 'urg', 'use', 'veri', 'vote', 'wa', 'want', 'way', 'work', 'xz', 'year', 'yield']\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=stemming_tokenizer, max_features=100)\n",
    "Xc100 = count_vectorizer.fit_transform(texts)\n",
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's push all of that into a dataframe with nicely named columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>allow</th>\n",
       "      <th>amend</th>\n",
       "      <th>american</th>\n",
       "      <th>amp</th>\n",
       "      <th>ani</th>\n",
       "      <th>appropri</th>\n",
       "      <th>associ</th>\n",
       "      <th>balanc</th>\n",
       "      <th>base</th>\n",
       "      <th>becaus</th>\n",
       "      <th>believ</th>\n",
       "      <th>chairman</th>\n",
       "      <th>children</th>\n",
       "      <th>china</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>trade</th>\n",
       "      <th>unit</th>\n",
       "      <th>urg</th>\n",
       "      <th>use</th>\n",
       "      <th>veri</th>\n",
       "      <th>vote</th>\n",
       "      <th>wa</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>xz</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   act  allow  amend  american  amp  ani  appropri  associ  balanc  base  \\\n",
       "0    3      1      2         3    0    0         0       0       4     0   \n",
       "1    1      1      1         0    0    0         0       0       2     0   \n",
       "2    1      0      0         1    0    0         0       0       1     0   \n",
       "\n",
       "   becaus  believ  chairman  children  china  ...    time  today  trade  unit  \\\n",
       "0       1       1         3         0      0  ...       3      2      0     1   \n",
       "1       1       0         2         0      0  ...       2      2      0     0   \n",
       "2       0       0         2         0      0  ...       0      0      0     0   \n",
       "\n",
       "   urg  use  veri  vote  wa  want  way  work  xz  year  yield  \n",
       "0    0    0     2     1   1     1    2     0   1     0      2  \n",
       "1    0    0     1     1   0     1    3     0   3     1      0  \n",
       "2    0    0     1     1   0     0    0     0   1     0      1  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xc = pd.DataFrame(Xc100.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "df_Xc.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone seems to start their speeches with \"mr chairman\" - how many speeches are there total, and many don't mention \"chairman\" and how many mention neither \"mr\" nor \"chairman\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "702"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xc['act'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xc[df_Xc[\"chairman\"]==0]['chairman'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Xc[df_Xc[\"mr\"]==0]['mr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 speaches in total do not mention neither 'mr' nor 'chairman'\n"
     ]
    }
   ],
   "source": [
    "total = df_Xc[df_Xc[\"mr\"]==0]['mr'].count() + df_Xc[df_Xc[\"chairman\"]==0]['chairman'].count()\n",
    "print(total,\"speaches in total do not mention neither 'mr' nor 'chairman'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the index of the speech thank is the most thankful, a.k.a. includes the word 'thank' the most times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>allow</th>\n",
       "      <th>amend</th>\n",
       "      <th>american</th>\n",
       "      <th>amp</th>\n",
       "      <th>ani</th>\n",
       "      <th>appropri</th>\n",
       "      <th>associ</th>\n",
       "      <th>balanc</th>\n",
       "      <th>base</th>\n",
       "      <th>becaus</th>\n",
       "      <th>believ</th>\n",
       "      <th>chairman</th>\n",
       "      <th>children</th>\n",
       "      <th>china</th>\n",
       "      <th>...</th>\n",
       "      <th>time</th>\n",
       "      <th>today</th>\n",
       "      <th>trade</th>\n",
       "      <th>unit</th>\n",
       "      <th>urg</th>\n",
       "      <th>use</th>\n",
       "      <th>veri</th>\n",
       "      <th>vote</th>\n",
       "      <th>wa</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>work</th>\n",
       "      <th>xz</th>\n",
       "      <th>year</th>\n",
       "      <th>yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   act  allow  amend  american  amp  ani  appropri  associ  balanc  base  \\\n",
       "0    3      1      2         3    0    0         0       0       4     0   \n",
       "1    1      1      1         0    0    0         0       0       2     0   \n",
       "4    0      0      1         0    0    0         1       0       1     0   \n",
       "\n",
       "   becaus  believ  chairman  children  china  ...    time  today  trade  unit  \\\n",
       "0       1       1         3         0      0  ...       3      2      0     1   \n",
       "1       1       0         2         0      0  ...       2      2      0     0   \n",
       "4       0       0         1         0      0  ...       1      0      0     0   \n",
       "\n",
       "   urg  use  veri  vote  wa  want  way  work  xz  year  yield  \n",
       "0    0    0     2     1   1     1    2     0   1     0      2  \n",
       "1    0    0     1     1   0     1    3     0   3     1      0  \n",
       "4    0    0     1     2   0     0    0     0   1     0      2  \n",
       "\n",
       "[3 rows x 100 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thank = df_Xc[df_Xc[\"thank\"]!=0]\n",
    "thank.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\radhika\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\ipykernel\\__main__.py:2: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "577    9\n",
       "Name: thank, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thank_column = thank['thank']\n",
    "thank_column.sort(inplace=False, ascending=False).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I'm searching for `China` and `trade`, what are the top 3 speeches to read according to the `CountVectoriser`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "china_trade = df_Xc['china'] + df_Xc['trade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\radhika\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "379    93\n",
       "399    37\n",
       "367    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "china_trade.sort(inplace=False, ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if I'm using a `TfidfVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=False, norm='l1')\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checking l2_vectorizer.get_feature_names()\n",
    "l2_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True)\n",
    "X = l2_vectorizer.fit_transform(texts)\n",
    "l2_df = pd.DataFrame(X.toarray(), columns=l2_vectorizer.get_feature_names())\n",
    "l2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What's the content of the speeches?** Here's a way to get them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# index 0 is the first speech, which was the first one imported.\n",
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pass that into 'cat' using { } which lets you put variables in shell commands\n",
    "# that way you can pass the path to cat\n",
    "!echo {paths[0]}\n",
    "!type a.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now search for something else!** Another two terms that might show up. `elections` and `chaos`? Whatever you thnik might be interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "election_chaos = df['elect'] + df['chao']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "election_chaos.sort(inplace=False, ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame([df['elect'], df['chao'], df['elect'] + df['chao']], index=[\"elect\", \"chao\", \"elect + chao\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enough of this garbage, let's cluster\n",
    "\n",
    "Using a **simple counting vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category.\n",
    "\n",
    "Using a **term frequency inverse document frequency vectorizer**, cluster the documents into **eight categories**, telling me what the top terms are per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "number_of_clusters = 8\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count vectorization\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = count_vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['text'] = texts\n",
    "results['category'] = km.labels_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['text'] = texts\n",
    "results['category'] = km.labels_\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = l2_vectorizer.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :5]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which one do you think works the best?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harry Potter time\n",
    "\n",
    "I have a scraped collection of Harry Potter fanfiction at https://github.com/ledeprogram/courses/raw/master/algorithms/data/hp.zip.\n",
    "\n",
    "I want you to read them in, vectorize them and cluster them. Use this process to find out **the two types of Harry Potter fanfiction**. What is your hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hp/hp\\\\10001898.txt',\n",
       " 'hp/hp\\\\10004131.txt',\n",
       " 'hp/hp\\\\10004927.txt',\n",
       " 'hp/hp\\\\10007980.txt',\n",
       " 'hp/hp\\\\10010343.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "paths = glob.glob('hp/hp/*')\n",
    "paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>filename</th>\n",
       "      <th>pathname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prologue: The MissionDisclaimer: All character...</td>\n",
       "      <td>hp\\10001898.txt</td>\n",
       "      <td>hp/hp\\10001898.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BlackDisclaimer: I do not own Harry PotterAuth...</td>\n",
       "      <td>hp\\10004131.txt</td>\n",
       "      <td>hp/hp\\10004131.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...</td>\n",
       "      <td>hp\\10004927.txt</td>\n",
       "      <td>hp/hp\\10004927.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Author's Note: Hey, just so you know, this is ...</td>\n",
       "      <td>hp\\10007980.txt</td>\n",
       "      <td>hp/hp\\10007980.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Disclaimer: I do not own Harry Potter and frie...</td>\n",
       "      <td>hp\\10010343.txt</td>\n",
       "      <td>hp/hp\\10010343.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content         filename  \\\n",
       "0  Prologue: The MissionDisclaimer: All character...  hp\\10001898.txt   \n",
       "1  BlackDisclaimer: I do not own Harry PotterAuth...  hp\\10004131.txt   \n",
       "2  Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...  hp\\10004927.txt   \n",
       "3  Author's Note: Hey, just so you know, this is ...  hp\\10007980.txt   \n",
       "4  Disclaimer: I do not own Harry Potter and frie...  hp\\10010343.txt   \n",
       "\n",
       "             pathname  \n",
       "0  hp/hp\\10001898.txt  \n",
       "1  hp/hp\\10004131.txt  \n",
       "2  hp/hp\\10004927.txt  \n",
       "3  hp/hp\\10007980.txt  \n",
       "4  hp/hp\\10010343.txt  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "for path in paths:\n",
    "    with open(path) as review_file:\n",
    "        review = {\n",
    "            'pathname': path,\n",
    "            'filename': path.split('/')[-1],\n",
    "            'content': review_file.read()\n",
    "        }\n",
    "    reviews.append(review)\n",
    "reviews_df = pd.DataFrame(reviews)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Prologue: The MissionDisclaimer: All character...\n",
       "1       BlackDisclaimer: I do not own Harry PotterAuth...\n",
       "2       Chapter 1\"I'm pregnant.\"\"\"\"Mum please say some...\n",
       "3       Author's Note: Hey, just so you know, this is ...\n",
       "4       Disclaimer: I do not own Harry Potter and frie...\n",
       "5       Disclaimer: I don't own any character in the H...\n",
       "6       DISCLAIMER: I don't own Harry Potter and its c...\n",
       "7       Katherine Rose-TylerChapter One: the Introduct...\n",
       "8       I am no longer that shy little boy anymore.I w...\n",
       "9       Happy New year! *throws confetti*I've really b...\n",
       "10      2014\"It's ridiculous.\" The red-headed boy shoo...\n",
       "11      Disclaimer: Did you really think I was J.K. Ro...\n",
       "12      This is my first story on fanfic and I'm nervo...\n",
       "13      DISCLAIMER: I don't own anything here that loo...\n",
       "14      A/N: So, this is my second ongoing story, and ...\n",
       "15      Disclaimer: I do not own Harry Potter. Enjoy t...\n",
       "16      For my friend, constant cheerleader and talent...\n",
       "17      Disclaimer: Harry Potter's not mineA/N:Another...\n",
       "18      Lily Potter was quite happy. Her favourite bro...\n",
       "19      A/N: This story follows all of canon besides f...\n",
       "20      It's 8th year at Hogwarts. Voldemort is dead. ...\n",
       "21      Hey everybody this is my first fic and will en...\n",
       "22      Prologue: The Puzzle That Wasn't Meant To Be S...\n",
       "23      Prologue REWRITTENA/N: This is a rewritten ver...\n",
       "24      I stood at the top of the Astronomy Tower thin...\n",
       "25      Title: Twin Dragon Heartstring Cores.Author: L...\n",
       "26      Chapter 1Walking down the corridor to potions,...\n",
       "27      These characters belong to J.K. Rowling, not m...\n",
       "28      A/N: Everyone needs their own version of a Sly...\n",
       "29      June 20th, 1992This was it. Dumbledore was sur...\n",
       "                              ...                        \n",
       "1298    Summary: Gryffindor isn't what Slytherin sees ...\n",
       "1299    Okay. Lumox. The title will be explained much ...\n",
       "1300    Normal Pov(A/N: Story takes place in Harry Pot...\n",
       "1301    (A/N: Rated M for mature content and language....\n",
       "1302    Hey you guys, I'm back!I wasn't planning on wr...\n",
       "1303    Truly, Madly, Deeply, Crazily In Love#Chapter ...\n",
       "1304    She took a deep breath as she lay in her hospi...\n",
       "1305    Chapter 1Beta Read by optimisticrealist72Thoug...\n",
       "1306    \"Now begin\", Dumbledore's voice boomed over th...\n",
       "1307    Hermione's POVShe grabbed another handful of r...\n",
       "1308    I thought it would be fun to make one of these...\n",
       "1309    Harry`s POVHarry Potter, boy who lived, chosen...\n",
       "1310    Okay, so I've been wanting to write a George/H...\n",
       "1311    A/N: Adopted from unwrittenlegacy. This will h...\n",
       "1312    . . . Sorry . . . Introduction . . . Not the F...\n",
       "1313    \"Why are we doing this again,\" Sirius asks gro...\n",
       "1314    I do not own any of the characters. You may ho...\n",
       "1315    Harry Potter, the Boy-Who-Lived, had always be...\n",
       "1316    Original Title: Dipping into the Dark SideOrig...\n",
       "1317    A/N: So I woke up the other day with this idea...\n",
       "1318    Author's Notes: In my own, happy little world,...\n",
       "1319    Title: Fighting For TomorrowRating: TSummary: ...\n",
       "1320    Bella Luna, beautiful moon. She wondered if he...\n",
       "1321    Authors note: Welcome to all the lovely reader...\n",
       "1322    AUTHOR'S NOTEHi everybody! This is my first fa...\n",
       "1323    I do not own Harry Potter and I only write for...\n",
       "1324    Hi everybody!Im so happy you clicked on this s...\n",
       "1325    I fell in love with this pairing and never loo...\n",
       "1326    Prologue: A Surrey StartEaster Saturday was pl...\n",
       "1327    \"Okay, who's going first?\" someone shouted ove...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts =reviews_df['content']\n",
    "texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize\n",
    "#### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemming_tokenizer(str_input):\n",
    "    \n",
    "    words = re.sub(r\"[^A-Za-z]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    #print(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=\"english\", tokenizer=stemming_tokenizer, max_features = 100)\n",
    "Z = count_vectorizer.fit_transform(texts)\n",
    "#print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(Z.toarray(), columns=count_vectorizer.get_feature_names()).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-efea2800b388>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstemming_tokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\radhika\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m     \u001b[1;31m##############################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\radhika\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;34m\"\"\"See the docstring for `spmatrix.toarray`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m         \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[0mfortran\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfortran\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\radhika\\appdata\\local\\programs\\python\\python35-32\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__numpy_ufunc__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=False, norm='l2')\n",
    "Z = tfidf_vectorizer.fit_transform(texts)\n",
    "pd.DataFrame(Z.toarray(), columns=tfidf_vectorizer.get_feature_names()).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
